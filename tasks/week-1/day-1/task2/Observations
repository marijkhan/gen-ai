======================================================================
              TASK 2: TOKENIZATION COMPARISON REPORT
         cl100k_base (GPT-4) vs o200k_base (GPT-4o)
======================================================================

----------------------------------------------------------------------
SETUP
----------------------------------------------------------------------

Tokenizers used:
  - cl100k_base: ~100k vocabulary (used by GPT-4, ChatGPT)
  - o200k_base:  ~200k vocabulary (used by GPT-4o)

Input: 30 strings across 5 categories
  - Code (6): Python, SQL, JS, HTML
  - Urdu/Deutsch Mix (6): Mixed-script sentences
  - Emoji (6): Simple, flags, compound ZWJ sequences
  - URL (6): Long query strings, API endpoints
  - JSON (6): Nested objects, arrays, unicode values


======================================================================
FINDING 1: Mixed-Script Text Costs More Than Sum of Parts
======================================================================

Test: Compare pure German, pure Urdu, and mixed sentences

  String                              cl100k    o200k
  ----------------------------------------------------------------
  "Guten Morgen" (pure German)            4        3
  "Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚº" (pure Urdu)               14        3
  Sum of parts                           18        6
  "Guten Morgen, Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ" (mixed)    21        8

RESULT: Mixed text costs MORE than the sum of individual parts.
  - cl100k: 21 tokens vs expected 18 (17% overhead)
  - o200k:   8 tokens vs expected  6 (33% overhead)

WHY: Each script switch forces a token boundary. The tokenizer
can't merge across script transitions, creating extra fragments
at every switch point.


======================================================================
FINDING 2: Flag Emojis Cost Far More Than Simple Emojis
======================================================================

Test: Compare simple emojis, flag emojis, and compound ZWJ emojis

  String                              cl100k    o200k
  ----------------------------------------------------------------
  "ðŸ˜€ðŸ”¥â¤ï¸" (3 simple emojis)              8        3
  "ðŸ‡µðŸ‡°" (1 flag emoji)                    6        4
  "ðŸ‡©ðŸ‡ª" (1 flag emoji)                    6        4
  "ðŸ‡µðŸ‡°ðŸ‡©ðŸ‡ªðŸ‡ºðŸ‡¸..." (10 flags)              60       40
  "ðŸ‘¨â€ðŸ‘©â€ðŸ‘§â€ðŸ‘¦" (1 family emoji)               18       11
  "ðŸ‘¨â€ðŸ’»" (1 compound emoji)                7        5

RESULT: A single flag emoji (ðŸ‡µðŸ‡°) costs MORE than 3 simple emojis combined.
  - 1 flag:   cl100k=6 tokens,  o200k=4 tokens
  - 3 emojis: cl100k=8 tokens,  o200k=3 tokens
  - 1 family: cl100k=18 tokens, o200k=11 tokens (most expensive single "character")
  - 10 flags: cl100k=60 tokens, o200k=40 tokens

WHY: Flag emojis are 2 regional indicator code points (8 bytes).
Family emojis are 4 person emojis joined by 3 zero-width joiners (25 bytes).
Neither tokenizer has vocabulary entries for these compound sequences,
so they fall back to byte-level tokenization.

Tokens per visual character:
  - Simple emoji: ~1-3 tokens
  - Flag emoji:   ~4-6 tokens
  - Family emoji: ~11-18 tokens


======================================================================
FINDING 3: JSON Costs 2-3x More Than Equivalent Plain Text
======================================================================

Test: Same data in JSON format vs plain text

  String                              cl100k    o200k
  ----------------------------------------------------------------
  {"name":"Ahmed","age":25,"city":"Berlin"}  19       18
  name Ahmed age 25 city Berlin              7        7
  RATIO                                    2.7x     2.6x

  {"users":[{"id":1...}],"total":2}         35       34
  users id 1 name Ali id 2 name Sara...     14       14
  RATIO                                    2.5x     2.4x

  {"config":{"model":"gpt-4"...}}           37       37
  model gpt-4 temperature 0.7...            21       21
  RATIO                                    1.8x     1.8x

RESULT: JSON consistently costs 1.8-2.7x more tokens than plain text.

WHY: Every structural character ({, }, [, ], ", :, ,) becomes a separate
token. These carry no information content â€” they're purely syntactic
overhead. The deeper the nesting, the higher the overhead.

IMPLICATION: When sending data to an LLM, consider whether JSON structure
is necessary. Plain text descriptions of the same data use significantly
fewer tokens, reducing cost and context window usage.


======================================================================
FINDING 4: o200k Does NOT Always Beat cl100k
======================================================================

Test: Compare token counts across categories

  Category            String                           cl100k   o200k   Winner
  --------------------------------------------------------------------------------------
  English             "Hello how are you today"            5       5     TIE
  English             "The quick brown fox..."            18      18     TIE
  English             "The capital of Pakistan..."        15      15     TIE
  German              "Hallo wie geht es Ihnen heute"     6       6     TIE
  Code                "for i in range(10): print(i)"     10      10     TIE
  JSON (English)      {"config":{"model":"gpt-4"...}}    37      37     TIE
  JSON (plain text)   model gpt-4 temperature...         21      21     TIE
  --------------------------------------------------------------------------------------
  Urdu                "ÛÛŒÙ„Ùˆ Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚº Ø¢Ø¬"              22       6     o200k (3.7x better)
  Urdu/German mix     "Guten Morgen, Ø¢Ù¾ Ú©ÛŒØ³Û’ ÛÛŒÚºØŸ"       21       8     o200k (2.6x better)
  Urdu long sentence  "Ù¾Ø§Ú©Ø³ØªØ§Ù† Ú©Ø§ Ø¯Ø§Ø±Ø§Ù„Ø­Ú©ÙˆÙ…Øª..."          71      23     o200k (3.1x better)

RESULT: For well-represented text (English, common code, German), both
tokenizers perform identically. o200k's larger vocabulary only helps
with underrepresented scripts like Urdu/Arabic.

WHY: Both tokenizers already have efficient entries for common English
words, code patterns, and major European languages. The extra 100k
tokens in o200k's vocabulary are allocated to less common scripts,
rare subwords, and multilingual coverage.

KEY INSIGHT: Switching to o200k only saves tokens (and cost) when
processing non-Latin scripts. For English-only workloads, there is
zero benefit.


======================================================================
FINDING 5: A Single URL Costs More Tokens Than a Full Paragraph
======================================================================

Test: Compare English prose vs URLs of similar length

  String (chars)                       cl100k    o200k
  ----------------------------------------------------------------
  English paragraph (90 chars)            18       18
  Google Maps URL (133 chars)             55       54
  Example.com URL (149 chars)             35       36
  GitHub API URL (118 chars)              35       35

RESULT: The Google Maps URL costs 3x more tokens than a full English
paragraph, despite being only 48% longer in characters.

Tokens per character ratio:
  - English prose: 0.20 tokens/char (5 chars per token)
  - URLs:          0.30-0.41 tokens/char (2.4-3.3 chars per token)

WHY: English words like "afternoon" or "beautiful" are single tokens.
URL components are fragmented by /, ., ?, =, & â€” each becoming a
separate token. Path segments, query parameter names, and values
rarely match vocabulary entries.

IMPLICATION: If passing URLs to an LLM, consider whether the full URL
is needed, or if a description of the resource would be more token-efficient.


======================================================================
SUMMARY TABLE
======================================================================

  Finding                            Confirmed?   Impact
  ------------------------------------------------------------------
  1. Mixed script > sum of parts     YES          17-33% overhead
  2. Flags >> simple emojis          YES          4-6x more per emoji
  3. JSON >> plain text              YES          1.8-2.7x more tokens
  4. o200k doesn't always win        YES          Identical for English/code
  5. URL > paragraph                 YES          2-3x more tokens


======================================================================
PRACTICAL TAKEAWAYS
======================================================================

  1. COST: If your workload is English-only, cl100k and o200k cost
     the same. Switch to o200k only for multilingual workloads.

  2. CONTEXT WINDOW: Avoid sending raw JSON or URLs when plain text
     descriptions would suffice â€” you'll fit 2-3x more content.

  3. MULTILINGUAL: Urdu/Arabic text uses 3-4x more tokens than English
     of equivalent meaning. Budget accordingly.

  4. EMOJIS: Avoid compound emojis (flags, families) in prompts.
     A single family emoji costs as much as a full English sentence.

  5. DATA FORMAT: When feeding structured data to LLMs, consider
     plain text over JSON to save 50-60% on tokens.